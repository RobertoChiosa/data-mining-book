
```{r, echo = FALSE, include = FALSE}
source("./scripts/packages.R") # load necessary packages
source("./scripts/boxplot_legend.R")
df <- read.csv("./data/week_not_clean.csv", header = TRUE, sep = ",", dec = ".", check.names = FALSE)
```

# Data cleaning

Raw data are not always cleaned and ready for the analyst to be processed. Usually there are many anomalies that have to be fixed before the analytics process. Typical problems that can generate anomalies in the data:

- Meter communication failed;
- Sensor break or modification;
- Intervention on the system (e.g. revamping of the heating/cooling system);
- Modification of the building usage;
- Catastrophic events.

Thus it is necessary to undergo a data preparation process that is usually the most time consuming task but also the most important. The process of "fixing" the data is called data cleaning and the main objective is to manage missing values, resolve inconsistencies, and detect and remove outliers. 

In the following, we will use as an example a portion of the dataset `df`. In particular we will consider just one week, shown in Figure \@ref(fig:scatter-week-raw).

```{r scatter-week-raw, echo = FALSE, fig.align = 'center', fig.cap="Example of not cleaned dataset.",}

p1<- ggplot(data =  df,
            aes(x = as.POSIXct(Date_Time, "%Y-%m-%d %H:%M:%S", tz = "Europe/Rome"),
                y =  Total_Power,
                color = Type
            )
) + 
  geom_point(na.rm = TRUE) + 
  scale_x_datetime(
    breaks = date_breaks("8 hour"),                     
    labels = date_format(("%H:%M") , tz = "Europe/Rome"),
    expand = c(0,0)                                     
  ) +
  scale_color_manual(values = c("blue", "red", "gray", "green")) + 
  theme_classic() +
  ggplot2::theme(
    legend.text = element_text(size = 10),
    legend.position = "top",                     # legend position on the top of the graph
    legend.direction = "horizontal",             # layout of items in legends
    legend.box = "horizontal",                   # arrangement of multiple legends
    strip.text = element_text(size = 10), # facet wrap title fontsize
    axis.title.x = element_text(size = 12,margin = margin(t = 20, r = 20, b = 0, l = 0)),
    axis.title.y = element_text(size = 12,margin = margin(t = 20, r = 20, b = 0, l = 0)),
    axis.text.x = element_text(size = 10, angle = 45, vjust=.0),
    axis.text.y = element_text(size = 10)
  ) + 
  guides(colour=guide_legend("", override.aes=list(colour=c("blue", "red", "gray", "green") ))) + 
  labs( x = "Hour" , y = "Electrical Load [kW]", legend = "")                    # axis label

ggMarginal(p1, type="boxplot", color = "blue", outlier.color = "green", margins = "y")
```

## Inconsistences


An obvious inconsistency is defined by @Paper2013 as:

> A record that contains a value or combination of values that cannot correspond to a real-world situation. 

For example measures related to an electrical load cannot be negative infinite or not a real number, and any of those values can be easely detected and removed.
 
However a particular knowledge of the measured data and systems is necessary to correctly evaluate inconsistences, which are not absolute but can vary depending on the situation.

Such knowledge can be expressed as rules or constraints. In our case study since the measures value refers to electrical load (i.e. power absorbed by the utility) we know a priori that any negative value can be marked as inconsistence.

```{r}
inconsistences <- df$Total_Power[df$Total_Power < 0]
```

The electrical load dataset contains `r sum(df$Type == "Inconsistence")` inconsistences (`r paste(inconsistences[!is.na(inconsistences)],"kW")`). Once identified they can be removed by substituting NA value.

```{r}
df$Total_Power[match(inconsistences, df$Total_Power)] <- NA
```

## Outliers
A general definition of outlier is provided by @Capozzoli2016:

> "Outliers are records that appear to deviate significantly from other elements in
the sample in which they occur. Outlier can be also defined as an observation (or subset of observations) that appears to be inconsistent with the remainder of that set of data."

In time series analysis, @Fan2015 defines the outliers as:

> "Observations unlikely to occur given the variance of the observations of the rest of the time series

The so called outliers can be distinguished into:

- Punctual outliers
- Sequence outliers.

In the data pre-processing phase, the identification of punctual outliers is needed, whenever infrequent sequential patterns could be detected through further investigation at a later stage.

### Inter-quartile method for punctual outlier identification

Detecting outliers with the interquartile method requires the calculation of three fundamental values:

- First quartile $Q_1$ : the point between the smallest value and the median (25% of the distribution) ;
- Second quartile or median $Q_2$ : the middle value of the dataset (50% of the distribution);
- Third quartile $Q_3$ : the point between median and the highest value (75% of the distribution);


The difference between the third and the first quartile is called Inter-Quartile Range $\text{IQR} = Q_3-Q_1$.

To detect the outliers is necessary to define an acceptability range and any data point lying outside this range are considered as outlier. The range is as given below:

\begin{equation}
R = [Q_2 − k \text{IQR}, Q_3 + k \text{IQR}]
\end{equation}

Where $k$ is an arbitrary parameters usually set at $1.5$. Any data point less than the Lower Bound or higher than the Upper Bound is considered as an *outlier*.

An effective way to visualize variables distributions and detect outliers is the boxplot (Section \@ref(sec:boxplots)) because it summarizes in a single plot all the statistics needed. Those statistics can be easily calculated through the R package `stats` as follows:

```{r}
Q1 = quantile(df$Total_Power, na.rm = T, c(0.25))  
Q2 = quantile(df$Total_Power, na.rm = T, c(0.50))  
Q3 = quantile(df$Total_Power, na.rm = T, c(0.75))  
Iqr = IQR(df$Total_Power, na.rm = T)               
k = 1.5
Lower_bound = Q1 - k*Iqr
Upper_bound = Q2 + k*Iqr
```

It is possible to identify the outliers by calculating the previous statistics and setting manually the range limits or by using the  `boxplot.stats` function which, given the $k$ coefficient, returns a list of values in which and `$out` is a vector of all the detected outliers. 
```{r}
outliers <- boxplot.stats(df$Total_Power, coef = k)$out
```

The electrical load dataset contains `r sum(df$Type == "Outlier")` outliers (`r paste(outliers,"kW")`). Once identified they can be removed by substituting NA value.

```{r}
df$Total_Power[match(outliers, df$Total_Power)] <- NA
```

### Z-score method for punctual outlier identification
Z-scores can quantify the unusualness of an observation when your data follow the normal distribution. Z- scores are the number of standard deviations above and below the mean that each value falls. A standard cut-off value for finding outliers are Z-scores of +/-3 or further from zero.

A given time series y(t) = {y1, . . . yn} of length n with mean μ and standard deviation σ is transformed into a new time series Z(t) = {Z1, . . . Zn} of length n with zero mean μ = 0 and unitary standard deviation σ = 1 through the equation (2.1).
Z(t) = y(t) − μ (2.1) σ
This process allows simplifying the analysis through the use of Z-scores, which is a measure of the position of data and represents how many standard deviations it is far from the mean of a standard normal distribution N(0,1). If the value is positive, the value lies above the mean; if negative it lies below. Z-scores allows to easily calculate the area under a normal Gaussian distribution and will be useful when dividing the distribution into equally probable areas.

\begin{equation}
\frac{y-y_1}{y_2-y_1}  = \frac{x-x_1}{x_2-x_1}
\end{equation}


## Missing values

A missing value consists in the lack of a given value or attribute in a dataset

In datasets the placeholder for missing value is NA

Common methods to handle missing values are global constant, local constant, moving average and interpolation.

### Global constant method 

substitute ALL the missing values in the data with a single value (e.g. Mean or Median value of the data).

### Local constant method 

substitute the missing values in the data with a values calculated locally. This process is carried out through Lookup Tables.

```{r}
data.frame(Day = c("Mon", "Tue"), Mean = c(1,2)) %>%
  knitr::kable(caption = "Raw gapminder data for Australia.")
```


### Moving Average or Simple Moving Average (SMA)

method substitute missing values with the unweighted mean of N previous valid measures.
$$
\begin{equation}
y = \frac{1}{N}\sum_{i=1}^n{y_{-i}}
\end{equation}
$$


### Linear interpolation method
substitute missing values with the values that lies on the straight line between two valid measures [(x0,y0),(x1,y1)].

$$
\begin{equation}
\frac{y-y_1}{y_2-y_1}  = \frac{x-x_1}{x_2-x_1}
\end{equation}
$$